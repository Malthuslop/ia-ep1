{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXTPDmf3mRMk"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from matplotlib import pyplot as plt\n",
    "import subprocess\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista_de_arquivos = []\n",
    "# for nome_do_arquivo in os.listdir('imagens/train/T'):\n",
    "#         # Verifica se é um arquivo (e não um diretório)\n",
    "#         if os.path.isfile(os.path.join('imagens/train/T', nome_do_arquivo)):\n",
    "#             lista_de_arquivos.append(nome_do_arquivo)\n",
    "# lista_de_arquivos.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indice_inicial = 413\n",
    "# for i in range(indice_inicial, len(lista_de_arquivos)):\n",
    "#     nome_atual = f'./imagens/train/T/{lista_de_arquivos[i]}'\n",
    "#     novo_indice = i + 1\n",
    "#     nome_novo = f'./imagens/train/T/{novo_indice}.png'\n",
    "#     os.rename(nome_atual, nome_novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"I\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "landmarks = [\"WRIST\",\n",
    "    \"THUMB_CMC\",\n",
    "    \"THUMB_MCP\",\n",
    "    \"THUMB_IP\",\n",
    "    \"THUMB_TIP\",\n",
    "    \"INDEX_FINGER_MCP\",\n",
    "    \"INDEX_FINGER_PIP\",\n",
    "    \"INDEX_FINGER_DIP\",\n",
    "    \"INDEX_FINGER_TIP\",\n",
    "    \"MIDDLE_FINGER_MCP\",\n",
    "    \"MIDDLE_FINGER_PIP\",\n",
    "    \"MIDDLE_FINGER_DIP\",\n",
    "    \"MIDDLE_FINGER_TIP\",\n",
    "    \"RING_FINGER_MCP\",\n",
    "    \"RING_FINGER_PIP\",\n",
    "    \"RING_FINGER_DIP\",\n",
    "    \"RING_FINGER_TIP\",\n",
    "    \"PINKY_MCP\",\n",
    "    \"PINKY_PIP\",\n",
    "    \"PINKY_DIP\",\n",
    "    \"PINKY_TIP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo o numero de arquivos de imagem de cada letra\n",
    "num_files = [] # cada elemento da lista é o numero de arquivos de imagem das letras em ordem alfabética\n",
    "for i,reps in enumerate(label):\n",
    "    # Caminho do diretório\n",
    "    directory = f'./imagens/test/{reps}'\n",
    "    # Executar comando bash para contar o número de arquivos\n",
    "    count_subprocess_result = subprocess.run(f'find {directory} -type f | wc -l', stdout=subprocess.PIPE, shell=True, text=True)\n",
    "    output = count_subprocess_result.stdout.strip()\n",
    "    num_files.append(int(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3FRXJ0emTKX"
   },
   "outputs": [],
   "source": [
    "  # Initialize the MediaPipe Hands object\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = 'test_centro_geometrico.csv'\n",
    "header = [f'Landmark{i}_{axis}' for i in range(0, 21) for axis in ['x', 'y', 'z']]\n",
    "header.append('label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir imagens_com_problemas_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm imagens_com_problemas_teste/* # Limpando o diretorio de imagens com problemas\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header) # Inserindo os nomes dos atributos\n",
    "    for i, reps in enumerate(label): \n",
    "        for j in range(1,num_files[i]+1):\n",
    "            newRow = []\n",
    "            if(reps == 'F' and j > 300):\n",
    "                k = j + 100\n",
    "            else:\n",
    "                k = j\n",
    "\n",
    "            caminho = \"imagens/test/\" + reps + \"/\" + str(k) + \".png\"\n",
    "            image = cv2.imread(caminho)\n",
    "            #image_bgr_resized = cv2.resize(image, (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "            # Convert the image to RGB format\n",
    "            try:\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                # Process the image with MediaPipe Hands\n",
    "                results = hands.process(image_rgb)\n",
    "                # Draw hand landmarks on the image\n",
    "                if results.multi_hand_landmarks:\n",
    "                    for hand_landmarks in results.multi_hand_world_landmarks:\n",
    "                        # Print the coordinates of the landmarks\n",
    "                        for landmark in hand_landmarks.landmark:\n",
    "                            newRow.append(landmark.x)\n",
    "                            newRow.append(landmark.y)\n",
    "                            newRow.append(landmark.z)\n",
    "                    newRow.append(reps)\n",
    "                    writer.writerow(newRow)\n",
    "                else:\n",
    "                    cv2.imwrite(\"imagens_com_problemas_teste/imagem\" + reps + \"00\" + str(k) + \".png\", image)\n",
    "            except Exception as e:\n",
    "                print(caminho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "id": "W_fY_cPli3gE",
    "outputId": "1fba54e9-f98d-48d0-bf2f-a90483c9bcc6"
   },
   "outputs": [],
   "source": [
    "# Draw hand landmarks on the image\n",
    "if results.multi_hand_landmarks:\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image_rgb, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "        # Print the coordinates of the landmarks\n",
    "        for landmark in hand_landmarks.landmark:\n",
    "            print(f\"Landmark coordinates: ({landmark.x}, {landmark.y}, {landmark.z})\")\n",
    "\n",
    "# Display the image with hand landmarks\n",
    "plt.imshow(image_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('treino_centro_geometrico.csv')\n",
    "df_train_sample = df_train.sample(n=10000)\n",
    "plt.figure(figsize=(30, 30))\n",
    "sns.scatterplot(x='Landmark8_x', y='Landmark8_y', hue='label', style='label', data=df_train_sample[(df_train_sample['label'] == 'D') | (df_train_sample['label'] == 'Q') | (df_train_sample['label'] == 'A') ], s=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(100, 100), random_state=1, max_iter = 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['label'])\n",
    "y_train = df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_centro_geometrico.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(columns=['label'])\n",
    "y_test = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_compare = pd.DataFrame(results == y_test)\n",
    "df_results_compare['label'].value_counts()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros\n",
    "image_size = (64, 64)  \n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "# Caminhos para os dados\n",
    "train_data_dir = 'imagens/train/'\n",
    "test_data_dir = 'imagens/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_generator.class_indices), activation='softmax'))  \n",
    "\n",
    "# Compilação do modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Resumo do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o modelo após o treinamento\n",
    "model.save('modelo_libras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotando a acurácia\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Acurácia do modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.show()\n",
    "\n",
    "# Plotando a perda\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Perda do modelo')\n",
    "plt.ylabel('Perda')\n",
    "plt.xlabel('Época')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do modelo\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print('Acurácia no conjunto de teste:', test_acc)\n",
    "\n",
    "# Mapeamento das classes\n",
    "class_indices = train_generator.class_indices\n",
    "print(\"Class Indices:\", class_indices)\n",
    "\n",
    "# Exemplo de uma previsão\n",
    "img_path = 'imagens/test/A/1.png'  # Exemplo de caminho da imagem\n",
    "img = tf.keras.preprocessing.image.load_img(img_path, target_size=image_size)\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "# Fazer a previsão\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "# Obter o nome da classe prevista\n",
    "classes = list(class_indices.keys())\n",
    "predicted_label = classes[predicted_class]\n",
    "print(\"Predicted Label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para exibir o resultado da classificação na câmera\n",
    "def display_classification(frame, predicted_letter):\n",
    "    # Adicionar o texto da classificação na imagem\n",
    "    cv2.putText(frame, f'Classificação: {predicted_letter}', (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "    \n",
    "    # Exibir a imagem com a classificação\n",
    "    cv2.imshow('Classificacao de Libras', frame)\n",
    "\n",
    "# Função para pré-processamento da imagem\n",
    "def preprocess_image(img):\n",
    "    img = cv2.resize(img, (64, 64))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    return img\n",
    "\n",
    "# Função para exibir o resultado da classificação\n",
    "def display_prediction(img, label):\n",
    "    cv2.putText(img, label, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "    cv2.imshow('Camera', img)\n",
    "\n",
    "# Inicializar a câmera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Erro ao capturar o frame da camera\")\n",
    "        break\n",
    "    \n",
    "    # Mostrar a câmera com um label inicial\n",
    "    display_prediction(frame, '\"Espaco\" -> classificar | \"Q\" -> sair')\n",
    "\n",
    "    # Verificar se a tecla \"Espaço\" foi pressionada\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(' '):\n",
    "        # Tirar uma foto (frame) e pré-processar\n",
    "        photo = preprocess_image(frame)\n",
    "        \n",
    "        # Fazer a previsão usando o modelo\n",
    "        prediction = model.predict(photo)\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        \n",
    "        # Mapear a classe prevista para a letra correspondente\n",
    "        classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W']\n",
    "        predicted_letter = classes[predicted_class]\n",
    "\n",
    "        # Exibir o resultado da classificação na câmera usando o OpenCV\n",
    "        display_classification(frame, predicted_letter)\n",
    "\n",
    "    # Fechar a câmera ao pressionar a tecla \"q\"\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
