{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros\n",
    "image_size = (64, 64)  \n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "# Caminhos para os dados\n",
    "train_data_dir = 'imagens/train/'\n",
    "test_data_dir = 'imagens/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_generator.class_indices), activation='softmax'))  \n",
    "\n",
    "# Compilação do modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Resumo do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o modelo após o treinamento\n",
    "model.save('modelo_libras_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotando a acurácia\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Acurácia do modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.show()\n",
    "\n",
    "# Plotando a perda\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Perda do modelo')\n",
    "plt.ylabel('Perda')\n",
    "plt.xlabel('Época')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do modelo\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print('Acurácia no conjunto de teste:', test_acc)\n",
    "\n",
    "# Mapeamento das classes\n",
    "class_indices = train_generator.class_indices\n",
    "print(\"Class Indices:\", class_indices)\n",
    "\n",
    "# Exemplo de uma previsão\n",
    "img_path = 'imagens/test/A/1.png'  # Exemplo de caminho da imagem\n",
    "img = tf.keras.preprocessing.image.load_img(img_path, target_size=image_size)\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "# Fazer a previsão\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "# Obter o nome da classe prevista\n",
    "classes = list(class_indices.keys())\n",
    "predicted_label = classes[predicted_class]\n",
    "print(\"Predicted Label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from interface_aplication_tools import display_classification, preprocess_image, display_prediction\n",
    "import time\n",
    "\n",
    "# Carregar o modelo treinado\n",
    "model = load_model('modelo_libras.h5')\n",
    "\n",
    "# Inicializar a câmera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Último tempo de captura\n",
    "last_capture_time = time.time()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Erro ao capturar o frame da camera\")\n",
    "        break\n",
    "    \n",
    "    # Mostrar a câmera com um label inicial\n",
    "    display_prediction(frame)\n",
    "\n",
    "    # Tempo atual\n",
    "    current_time = time.time()\n",
    "    \n",
    "    # Verificar se 0.5 segundos passaram desde a última captura\n",
    "    if current_time - last_capture_time >= 0.5:\n",
    "        last_capture_time = current_time\n",
    "        \n",
    "        # Tirar uma foto (frame) e pré-processar\n",
    "        photo = preprocess_image(frame)\n",
    "\n",
    "        # Fazer a previsão usando o modelo\n",
    "        prediction = model.predict(photo)\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        \n",
    "        # Mapear a classe prevista para a letra correspondente\n",
    "        classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W']\n",
    "        predicted_letter = classes[predicted_class]\n",
    "\n",
    "        # Exibir o resultado da classificação na câmera usando o OpenCV\n",
    "        display_classification(frame, predicted_letter)\n",
    "        \n",
    "        # Extrair a imagem pré-processada para visualização\n",
    "        preprocessed_img = (photo[0] * 255).astype('uint8')  # Remover a dimensão adicional e reescalar\n",
    "        cv2.imshow('Imagem Pre-processada', cv2.resize(preprocessed_img, (256, 256)))  # Redimensionar para facilitar a visualização\n",
    "\n",
    "    # Fechar a câmera ao pressionar a tecla \"q\"\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
